#Dlib is released under Boost Software License
"""
Boost Software License - Version 1.0 - August 17th, 2003

Permission is hereby granted, free of charge, to any person or organization
obtaining a copy of the software and accompanying documentation covered by
this license (the "Software") to use, reproduce, display, distribute,
execute, and transmit the Software, and to prepare derivative works of the
Software, and to permit third-parties to whom the Software is furnished to
do so, all subject to the following:

The copyright notices in the Software and this entire statement, including
the above license grant, this restriction and the following disclaimer,
must be included in all copies of the Software, in whole or in part, and
all derivative works of the Software, unless such copies or derivative
works are solely in the form of machine-executable object code generated by
a source language processor.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE, TITLE AND NON-INFRINGEMENT. IN NO EVENT
SHALL THE COPYRIGHT HOLDERS OR ANYONE DISTRIBUTING THE SOFTWARE BE LIABLE
FOR ANY DAMAGES OR OTHER LIABILITY, WHETHER IN CONTRACT, TORT OR OTHERWISE,
ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER
DEALINGS IN THE SOFTWARE.
"""

#importing needed modules
import dlib
import cv2
import numpy as np
import time
import os
import threading
from queue import Queue
from multiprocessing.pool import ThreadPool
import pickle
import socket
import string
import secrets
import LiveView.models as database
from django.utils import timezone
from LiveView import views
from webpush import send_user_notification


class FaceRecognition:
    def __init__(self, models_paths):
        #resize factor, incorrectly called crop factor in the documentation and models. It's a typo.
        self.resize_factor = float(database.Setting.objects.get(pk=1).crop)
        #device got form database
        self.device = database.Setting.objects.get(pk=1).device
        #neccessary models for shape prediction and face recognition
        self.models = models_paths
        self.dir = os.path.join(os.path.dirname(__file__), "..")
        #creates a Queue for frames got camera
        self.frameQ = Queue()

        #lists of descriptors, all names
        self.descriptors = []
        self.names = []

        #counts blinks in the blink detector
        self.blink_frame_count = 0
        self.frame_count = 0

        #variables for the access function
        self.auth_count = 0
        self.unknown_count = 0
        self.empty_count1 = 0
        self.empty_count2 = 0
        self.trigtime = 0

        #creating dlib objects, face detector, shape (landmark) detector and the facial recognition itself
        self.detector = dlib.get_frontal_face_detector()
        self.predictor5 = dlib.shape_predictor(self.models[0])
        self.facerec_model = dlib.face_recognition_model_v1(self.models[1])


        #LAN information
        self.host = ""
        self.port1 = 13081
        self.port2 = 13082

        self.count = 0
        self.countStarted = False

        #loading data
        self.persons = database.Person.objects.all()
        self.pks = list(self.persons.values_list('id', flat=True))
        print("primary keys have been loaded")
        self.names = list(self.persons.values_list('name', flat=True))
        print("names have been loaded")
        self.files = list(self.persons.values_list('file', flat=True))
        print("images have been loaded")


    #draws the bounding rectangle to every processed frame
    def draw(self, img, rect):
        (x, y, w, h) = rect
        cv2.rectangle(img, (x, y), (x + w, y + h), (0, 255, 0), 2)

    #prints name of the person to every processed frame
    def PrintText(self, img, text, x, y):
        cv2.putText(img, text, (x, y), cv2.FONT_HERSHEY_PLAIN, 1.5, (0, 255, 0), 2)

    #resizes frames
    def resize_img(self, img, fx=0.25, fy=0.25):
        return cv2.resize(img, (0, 0), fx=fx, fy=fy)

    #convers dlib coordinates to opencv coordinates
    def dlib2opencv(self, dlib_rect):
        x = dlib_rect.left()
        y = dlib_rect.top()
        w = dlib_rect.right()
        h = dlib_rect.bottom()
        return [x, y, w - x, h - y]

    #loads static images of known persons
    def load_image(self, filename):
        img = cv2.imread(filename)
        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        # img = cv2.equalizeHist(img)
        return img

    #releases video capture
    def release_cap(self):
        self.cap.release()

    #grabs video capture
    def grab_cap(self):
        self.resize_factor = float(database.Setting.objects.get(pk=1).crop)
        self.device = database.Setting.objects.get(pk=1).device
        # self.device = "/home/user/PycharmProjects/resource/rebs2.mp4"
        self.cap = cv2.VideoCapture(self.device)

    #loads neccessary files
    def load_files(self):
        self.device = database.Setting.objects.get(pk=1).device
        print("Device has been loaded")
        self.resize_factor = float(database.Setting.objects.get(pk=1).crop)
        print("crop factor has been loaded")
        self.persons = database.Person.objects.all()
        self.pks = list(self.persons.values_list('id', flat=True))
        print("primary keys have been loaded")
        self.names = list(self.persons.values_list('name', flat=True))
        print("names have been loaded")
        self.files = list(self.persons.values_list('file', flat=True))
        print("images have been loaded")
        try:
            with open('descriptors.pkl', 'rb') as infile:
                self.descriptors = pickle.load(infile)
            print("descriptors have been loaded")
            infile.close()

        except FileNotFoundError:
            print("file descriptors.pkl not found")
            if input("Do you want to run the known people encoding? y/n: ").lower() == 'y':
                self.known_subjects_descriptors(None)
                with open('descriptors.pkl', 'rb') as infile:
                    self.descriptors = pickle.load(infile)
                print("descriptors have been loaded")
                infile.close()
            else:
                print("terminating")
                exit(101)

        return True

    #computes descriptors of known persons (all faces in the person table)
    def known_subjects_descriptors(self, paths):
        descriptors = []
        self.dir = os.path.join(os.path.dirname(__file__), "..")
        if paths == None:
            for i in range(0, len(self.files)):
                full_path = self.dir + "/media/" + self.files[i]
                print("processing: ", full_path)
                img = self.load_image(full_path)
                face = self.detector(img, 1)
                if len(face) != 0:
                    landmarks = self.predictor5(img, face[0])
                    descriptors.append(np.array(self.facerec_model.compute_face_descriptor(img, landmarks)))
                else:
                    print("No face in picture {}".format(full_path))
                    database.Person.objects.filter(name=self.names[i]).delete()
                    print("record deleted from database")

            with open('descriptors.pkl', 'wb') as outfile:
                pickle.dump(descriptors, outfile, pickle.HIGHEST_PROTOCOL)
            outfile.close()
            print("descriptors of known people has been saved")

        else:
            for i in range(0, len(paths)):
                full_path = self.dir + "/media/" + paths[i]
                print("processing: ", full_path)
                img = self.load_image(full_path)
                face = self.detector(img, 1)
                if len(face) != 0:
                    landmarks = self.predictor5(img, face[0])
                    descriptors.append(self.facerec_model.compute_face_descriptor(img, landmarks))
                else:
                    print("No face in picture {}".format(full_path))
                    database.Log.objects.filter(snapshot=paths[i]).delete()
                    print("record deleted from database")
            return descriptors


    #detects faces in frames
    def detect(self, img):
        faces = self.detector(img, 1)
        if len(faces) != 0:
            return faces
        else:
            return None

    #finds landmarks in frames using the shape predictor
    def find_landmarks(self, img, faces):
        landmarks = []
        for face in faces:
            landmarks.append(self.predictor5(img, face))
        return landmarks

    #computes descriptors
    def descriptor(self, img, landmarks):
        return np.array(self.facerec_model.compute_face_descriptor(img, landmarks))

    #compares 2 faces in 128D space
    def compare(self, known, unknown):
        #the commented code is an alternative version for explanatory reasons, gives the same results
        # all = []
        # for x in known:
        #     temp = 0
        #     for y in range(len(x)):
        #         temp = (x[y]-unknown[y])**2 + temp
        #     all.append(math.sqrt(temp))
        # print(all)
        return np.linalg.norm(known - unknown, axis=1)

    #reads stream from a camera, runs neccessary image processings and puts every frame to frameQ
    def read_stream(self):
        this_frame = True
        while True:
            if views.rec_threads.stream_thread.stopped():
                print("stream killed")
                self.frameQ.task_done()
                break
            ret, frame = self.cap.read()
            if frame is not None:
                #process every other frame
                if this_frame:
                    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                    self.frameQ.put(frame)
                this_frame = not this_frame
        return

    #main function, puts everything needed for facial rec. together
    def process(self):
        labels = []
        crop = None
        image = self.frameQ.get()
        frame = self.resize_img(image, fx=self.resize_factor, fy=self.resize_factor)
        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)
        faces = self.detect(frame)
        #if there are any faces in the frame
        if faces is not None:
            landmarks = self.find_landmarks(frame, faces)
            #for every faces do following
            for i in range(0, len(faces)):
                #convert coordinate systems
                rect = self.dlib2opencv(faces[i])
                #draw a rectangle
                self.draw(frame, rect)
                (x,y,w,h) = rect
                x = x*4
                y = y*4
                w = w*4
                h = h*4
                crop = image[y: y+h, x: x+w]
                #create list of comparisons by comparing the tested faces against every face in the database
                comparisons = (self.compare(self.descriptors, self.descriptor(frame, landmarks[i]))).tolist()
                #do for every comparison in the list comparisons

                if np.amin(comparisons) <= 0.55:
                    label = np.argmin(comparisons)
                else:
                    label = None

                try:
                    self.PrintText(frame, self.names[int(label)], rect[0], rect[1])
                except IndexError:
                    print("Person does not exist anymore, you have most likely forgotten to load files.")
                except TypeError:
                    self.PrintText(frame, "unknown", rect[0], rect[1])

                labels.append(label)
        frame = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)
        # self.outputQ.put(frame)
        # cv2.imshow("SmartGate", image)
        # cv2.waitKey(1)
        return labels, frame, crop


    #manages access and writes logs to database
    def access(self, labels, image):
        #if no face in frame
        if not labels:
            self.empty_count1 += 1
            self.empty_count2 += 1
        else:
            for label in labels:
                #if label is none (the person is unknown)
                if label is None:
                    self.unknown_count += 1

                    if (self.empty_count1 > 8) and self.unknown_count > 8:
                        text = ''.join(secrets.choice(string.ascii_uppercase + string.digits + string.ascii_lowercase) for _ in range(20))
                        fullpath = self.dir+"/media/snapshots/"+text+".jpg"
                        djangopath = "snapshots/"+text+".jpg"

                        if self.countStarted:
                            self.count += 1
                            if cv2.imwrite(fullpath, image):
                                print("snap saved")
                            self.unknown_count = 0
                            self.empty_count1 = 0
                            log = database.Log.objects.create(person=None,time=timezone.now(), snapshot=djangopath)
                            log.save()
                            print(self.count)

                else:
                    self.auth_count += 1
                    if (self.empty_count2 > 10) and self.auth_count > 5:
                        self.empty_count2 = 0
                        self.auth_count = 0
                        name = self.names[label]
                        print("access denied for: ", name)
                        person = database.Person.objects.get(name=name)
                        log = database.Log.objects.create(person=person, time=timezone.now(), snapshot=None)
                        log.save()


    def filter(self):
        logs = database.Log.objects.all()
        snaps = list(logs.values_list('snapshot', flat=True))
        snaps = list(filter(None, snaps))
        descriptors = self.known_subjects_descriptors(snaps)
        labels = dlib.chinese_whispers_clustering(descriptors,0.5)
        print(labels)
        num_classes = len(set(labels))
        print("Number of people: ", num_classes)
        return num_classes




        
